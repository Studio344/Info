# UCFitness Dev Log: Battling Fitbit API Rate Limits

## Introduction

**UCFitness** is a fitness tracker web application I'm building as a personal project. It aggregates step counts, heart rate, calories burned, and other data from Fitbit wearable devices, then displays competitive rankings among users. The tech stack includes **Next.js (App Router)**, **Supabase**, and **Tailwind CSS**.

In this article, I'll document in detail the biggest technical challenge I faced during development: the **Fitbit Web API Rate Limit**, and the architectural decisions that led to its resolution.

## The Problem: Fitbit API Rate Limits

The Fitbit Web API enforces a strict limit of **150 requests per user per hour**. While this might seem generous at first glance, an application like UCFitness can quickly exhaust this quota for several reasons:

- **Multiple endpoints per user**: Fetching steps, heart rate, calories, and sleep data requires 4-6 separate API calls per user
- **Date range queries**: Retrieving weekly or monthly data sometimes requires individual requests per day
- **Concurrent user access**: The ranking feature needs fresh data for all participants simultaneously
- **Frontend-triggered requests**: A naive design where each page load calls the API directly hits limits fast

The initial implementation was particularly problematic — it called the Fitbit API directly every time a user opened the page. With just 10 concurrent users, we were dangerously close to the hourly limit.

## The Solution: Batch Fetching + Cache Architecture

To fundamentally solve this problem, I designed a three-layer architecture:

### 1. Next.js API Routes (Server-Side Proxy)

Instead of calling the Fitbit API directly from the frontend, I introduced **Next.js API Routes** as an intermediary layer. This provided:

- Secure server-side management of API keys and access tokens
- Server-side control over request frequency
- Centralized error handling and retry logic

### 2. Supabase Data Cache

Data fetched from the Fitbit API is stored in **Supabase (PostgreSQL)**, and the frontend reads from this cache instead of hitting the external API.

- Data freshness is tracked via an `updated_at` column
- Requests within the cache window (e.g., 15 minutes) are served from Supabase
- Only cache misses trigger actual Fitbit API calls

### 3. Background Batch Processing

The most impactful change was implementing **scheduled batch processing**. Using Vercel's serverless environment, all user data is fetched periodically and stored in Supabase in bulk.

- Complete separation between user page visits and API calls
- Mathematically controlled rate limit usage (users × endpoints ÷ time)
- Dramatically faster frontend response times (no API latency)

## Results

This architectural overhaul delivered significant improvements:

| Metric | Before | After |
|--------|--------|-------|
| Page load time | 2-3 seconds (waiting for API) | Under 200ms (cache read) |
| Rate limit hits | Frequent | Nearly zero |
| API request efficiency | Users × page views | A few batch runs per day |

## Lessons Learned

When building applications that depend on external APIs, **designing your architecture around API constraints from the start** is critical. While the "build first, optimize later" approach has its merits, hard constraints like rate limits should be factored into the design early on.

Additionally, Supabase's real-time subscription feature makes it possible to reflect batch-updated data on the frontend instantly, minimizing API calls without sacrificing user experience.

Looking ahead, I'm keeping an eye on Fitbit's webhook capabilities and planning a potential migration to **push-based data updates** as the API ecosystem evolves.
